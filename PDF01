import os
import re
import shutil
from pathlib import Path
from collections import defaultdict

# Define input/output paths
source_dir = Path(r"D:\AA039\PDFs_PreProcessed")
output_dir = Path(r"D:\AA039\PDFs_PostProcessed")
output_dir.mkdir(parents=True, exist_ok=True)

# Define regex to extract base name and revision
revision_pattern = re.compile(r"^(.*)_Revision_([A-Z]|\d+)\.pdf$", re.IGNORECASE)

# Step 1: Remove duplicates ending in (1).pdf
all_files = [f for f in source_dir.glob("*.pdf") if not f.name.endswith("(1).pdf")]

# Step 2: Process files to find latest revisions
revision_groups = defaultdict(list)
unmatched_files = []

def revision_sort_key(rev):
    if rev.isalpha():
        # Treat letters as oldest, convert to number with a lower offset (e.g., A=0, B=1...)
        return (0, ord(rev.upper()) - ord('A'))
    elif rev.isdigit():
        return (1, int(rev))
    else:
        return (2, rev)  # fallback for unexpected cases

for file in all_files:
    match = revision_pattern.match(file.name)
    if match:
        base_name = match.group(1)
        revision = match.group(2)
        revision_groups[base_name].append((revision, file))
    else:
        unmatched_files.append(file)

# Step 3: Copy latest revision of each group
for base, revs in revision_groups.items():
    # Sort by our custom revision logic
    revs_sorted = sorted(revs, key=lambda x: revision_sort_key(x[0]), reverse=True)
    latest_file = revs_sorted[0][1]
    shutil.copy2(latest_file, output_dir / latest_file.name)

# Step 4: Copy unmatched files
for file in unmatched_files:
    shutil.copy2(file, output_dir / file.name)

print(f"Processed {len(all_files)} PDFs.")
print(f"Copied {len(revision_groups)} latest revision files and {len(unmatched_files)} unmatched files.")
